{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Content-Aware Video Cropping (Single Video at a time)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23481,
     "status": "ok",
     "timestamp": 1735974719023,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "2RN8IqUmgYld",
    "outputId": "053b4856-57d7-4861-dc67-4a36f3c5672b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.57-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.57-py3-none-any.whl (905 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.3/905.3 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.57 ultralytics-thop-2.0.13\n",
      "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.1)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.12.14)\n",
      "\u001b[33mWARNING: supervision 0.25.1 does not provide the extra 'assets'\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.7/213.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.4/727.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install moviepy\n",
    "!pip install -q supervision[assets] jupyter_bbox_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>For reproducing the results, make sure to mount the correct drive, and then change the part according to the location of dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1735974719023,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "9AmgMCKqTcMP"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'yolo11n-seg.pt'\n",
    "MAIN_INPUT_PATH = '/content/drive/MyDrive/Genuin Assignment/single_class_ip/2FgBOgck_K0.mp4'\n",
    "ANNOTATED_OUTPUT_PATH = '/content/annotated_output_video.mp4'\n",
    "MAIN_OUTPUT_PATH = '/content/output_video.mp4'\n",
    "DETECTIONS_FILE_PATH = '/content/detections.jsonl'\n",
    "DESTINATION_FOLDER = '/content/drive/MyDrive/Solutions/eleven.mp4'\n",
    "OUTPUT_WIDTH = 1080\n",
    "OUTPUT_HEIGHT = 1920\n",
    "\n",
    "# Batch processing parameters\n",
    "BATCH_SIZE = 128  # Reduced batch size for memory efficiency\n",
    "TARGET_SIZE = (640, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36160,
     "status": "ok",
     "timestamp": 1735974755178,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "VPDmS3b7hU4L",
    "outputId": "46cf77e1-970c-4157-b274-c0fb9c002d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1735974755178,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "IkzCnYeXojve",
    "outputId": "5e8f213e-9c17-42fb-9f13-2b5084af7954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1735974756993,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "ZvW-8Q-rQQkO",
    "outputId": "c07da6d6-1e07-4788-cba2-6bbb20a63486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720 23 625\n"
     ]
    }
   ],
   "source": [
    "obj = sv.VideoInfo.from_video_path(MAIN_INPUT_PATH)\n",
    "width, height, fps, total_frames = obj.width, obj.height, obj.fps, obj.total_frames\n",
    "print(width, height, fps, total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1962,
     "status": "ok",
     "timestamp": 1735974758951,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "ncQfqOrZm2i_",
    "outputId": "a663e532-6a2a-45f2-e1c1-14be9edda39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.90M/5.90M [00:00<00:00, 259MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): SegmentationModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): C2PSA(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): PSABlock(\n",
       "            (attn): Attention(\n",
       "              (qkv): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (proj): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (pe): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (ffn): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (12): Concat()\n",
       "      (13): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (15): Concat()\n",
       "      (16): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (18): Concat()\n",
       "      (19): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (21): Concat()\n",
       "      (22): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): Segment(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (proto): Proto(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (upsample): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv4): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(MODEL_NAME)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1735974796478,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "94JwChagKbOY"
   },
   "outputs": [],
   "source": [
    "def save_detection(detection_data, file_path):\n",
    "    with open(file_path, 'a') as f:\n",
    "        json.dump(detection_data, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "def process_frame_batch(frames, indices, cap_props):\n",
    "    width, height = int(cap_props['width']), int(cap_props['height'])\n",
    "    processed_frames = []\n",
    "\n",
    "    # Process each frame\n",
    "    for frame in frames:\n",
    "        # Resize and preprocess\n",
    "        resized_frame = cv2.resize(frame, TARGET_SIZE)\n",
    "        frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_normalized = frame_rgb.astype(np.float32) / 255.0\n",
    "        processed_frames.append(frame_normalized)\n",
    "\n",
    "    # Convert to tensor\n",
    "    frames_array = np.stack(processed_frames)\n",
    "    frames_tensor = torch.from_numpy(frames_array).permute(0, 3, 1, 2)\n",
    "\n",
    "    # Free up memory\n",
    "    del processed_frames, frames_array\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Run detection\n",
    "    results = model(frames_tensor, stream=True)\n",
    "\n",
    "    # Process results and save\n",
    "    for idx, (result, orig_frame) in enumerate(zip(results, frames)):\n",
    "        frame_num = indices[idx]\n",
    "\n",
    "        # Scale factors\n",
    "        scale_x = width / TARGET_SIZE[0]\n",
    "        scale_y = height / TARGET_SIZE[1]\n",
    "\n",
    "        # Create detection data\n",
    "        frame_detections = {\n",
    "            'frame_number': frame_num,\n",
    "            'detections': []\n",
    "        }\n",
    "\n",
    "        if hasattr(result, 'boxes') and len(result.boxes) > 0:\n",
    "            for box, cls in zip(result.boxes.xyxy, result.boxes.cls):\n",
    "                # Scale coordinates\n",
    "                scaled_box = [\n",
    "                    float(box[0].item() * scale_x),\n",
    "                    float(box[1].item() * scale_y),\n",
    "                    float(box[2].item() * scale_x),\n",
    "                    float(box[3].item() * scale_y)\n",
    "                ]\n",
    "\n",
    "                detection = {\n",
    "                    'class': result.names[int(cls)],\n",
    "                    'confidence': float(box.conf) if hasattr(box, 'conf') else None,\n",
    "                    'bbox': scaled_box\n",
    "                }\n",
    "\n",
    "                frame_detections['detections'].append(detection)\n",
    "\n",
    "        # Save detection data\n",
    "        save_detection(frame_detections, DETECTIONS_FILE_PATH)\n",
    "\n",
    "def process_video():\n",
    "    # Open video capture\n",
    "    cap = cv2.VideoCapture(MAIN_INPUT_PATH)\n",
    "\n",
    "    # Get video properties\n",
    "    cap_props = {\n",
    "        'width': cap.get(cv2.CAP_PROP_FRAME_WIDTH),\n",
    "        'height': cap.get(cv2.CAP_PROP_FRAME_HEIGHT),\n",
    "        'fps': cap.get(cv2.CAP_PROP_FPS)\n",
    "    }\n",
    "\n",
    "    frames_batch = []\n",
    "    frame_indices = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frames_batch.append(frame)\n",
    "        frame_indices.append(frame_count)\n",
    "\n",
    "        if len(frames_batch) == BATCH_SIZE:\n",
    "            try:\n",
    "              process_frame_batch(frames_batch, frame_indices, cap_props)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch at frame {frame_count}: {str(e)}\")\n",
    "\n",
    "            # Clear batch\n",
    "            frames_batch = []\n",
    "            frame_indices = []\n",
    "            torch.cuda.empty_cache()  # Clear CUDA cache\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 10 == 0:\n",
    "            print(f\"Processed frame {frame_count}\")\n",
    "\n",
    "    # Process remaining frames\n",
    "    if frames_batch:\n",
    "        try:\n",
    "          process_frame_batch(frames_batch, frame_indices, cap_props)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing final batch: {str(e)}\")\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Detections jsonl data saved\")\n",
    "\n",
    "def load_detections():\n",
    "    detections = []\n",
    "    with open(DETECTIONS_FILE_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            detections.append(json.loads(line))\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25988,
     "status": "ok",
     "timestamp": 1735974822464,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "tDwc4oSqmWRv",
    "outputId": "1fe67890-0e12-49a6-dfd9-0f68434c8a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame 10\n",
      "Processed frame 20\n",
      "Processed frame 30\n",
      "Processed frame 40\n",
      "Processed frame 50\n",
      "Processed frame 60\n",
      "Processed frame 70\n",
      "Processed frame 80\n",
      "Processed frame 90\n",
      "Processed frame 100\n",
      "Processed frame 110\n",
      "Processed frame 120\n",
      "\n",
      "0: 640x640 2 persons, 6.3ms\n",
      "1: 640x640 2 persons, 6.3ms\n",
      "2: 640x640 2 persons, 6.3ms\n",
      "3: 640x640 2 persons, 6.3ms\n",
      "4: 640x640 2 persons, 6.3ms\n",
      "5: 640x640 2 persons, 6.3ms\n",
      "6: 640x640 2 persons, 6.3ms\n",
      "7: 640x640 2 persons, 1 chair, 6.3ms\n",
      "8: 640x640 2 persons, 1 chair, 6.3ms\n",
      "9: 640x640 2 persons, 1 chair, 6.3ms\n",
      "10: 640x640 2 persons, 1 chair, 6.3ms\n",
      "11: 640x640 2 persons, 1 chair, 6.3ms\n",
      "12: 640x640 2 persons, 1 chair, 6.3ms\n",
      "13: 640x640 2 persons, 1 chair, 6.3ms\n",
      "14: 640x640 2 persons, 6.3ms\n",
      "15: 640x640 2 persons, 1 chair, 6.3ms\n",
      "16: 640x640 2 persons, 1 chair, 6.3ms\n",
      "17: 640x640 2 persons, 1 chair, 6.3ms\n",
      "18: 640x640 2 persons, 1 chair, 6.3ms\n",
      "19: 640x640 2 persons, 1 chair, 6.3ms\n",
      "20: 640x640 2 persons, 1 chair, 6.3ms\n",
      "21: 640x640 2 persons, 1 chair, 6.3ms\n",
      "22: 640x640 2 persons, 1 chair, 6.3ms\n",
      "23: 640x640 2 persons, 1 chair, 6.3ms\n",
      "24: 640x640 2 persons, 1 chair, 6.3ms\n",
      "25: 640x640 2 persons, 1 chair, 6.3ms\n",
      "26: 640x640 2 persons, 1 chair, 6.3ms\n",
      "27: 640x640 2 persons, 1 chair, 6.3ms\n",
      "28: 640x640 2 persons, 6.3ms\n",
      "29: 640x640 2 persons, 1 chair, 6.3ms\n",
      "30: 640x640 2 persons, 6.3ms\n",
      "31: 640x640 2 persons, 6.3ms\n",
      "32: 640x640 2 persons, 6.3ms\n",
      "33: 640x640 2 persons, 6.3ms\n",
      "34: 640x640 2 persons, 6.3ms\n",
      "35: 640x640 2 persons, 6.3ms\n",
      "36: 640x640 2 persons, 6.3ms\n",
      "37: 640x640 2 persons, 6.3ms\n",
      "38: 640x640 2 persons, 6.3ms\n",
      "39: 640x640 2 persons, 6.3ms\n",
      "40: 640x640 2 persons, 6.3ms\n",
      "41: 640x640 2 persons, 6.3ms\n",
      "42: 640x640 2 persons, 6.3ms\n",
      "43: 640x640 2 persons, 6.3ms\n",
      "44: 640x640 2 persons, 6.3ms\n",
      "45: 640x640 2 persons, 1 chair, 6.3ms\n",
      "46: 640x640 2 persons, 6.3ms\n",
      "47: 640x640 2 persons, 1 chair, 6.3ms\n",
      "48: 640x640 2 persons, 6.3ms\n",
      "49: 640x640 2 persons, 1 chair, 6.3ms\n",
      "50: 640x640 2 persons, 1 chair, 6.3ms\n",
      "51: 640x640 2 persons, 6.3ms\n",
      "52: 640x640 2 persons, 1 chair, 6.3ms\n",
      "53: 640x640 2 persons, 1 chair, 6.3ms\n",
      "54: 640x640 2 persons, 1 chair, 6.3ms\n",
      "55: 640x640 2 persons, 1 chair, 6.3ms\n",
      "56: 640x640 2 persons, 1 chair, 6.3ms\n",
      "57: 640x640 2 persons, 1 chair, 6.3ms\n",
      "58: 640x640 2 persons, 1 chair, 6.3ms\n",
      "59: 640x640 2 persons, 1 chair, 6.3ms\n",
      "60: 640x640 2 persons, 6.3ms\n",
      "61: 640x640 2 persons, 6.3ms\n",
      "62: 640x640 2 persons, 6.3ms\n",
      "63: 640x640 2 persons, 6.3ms\n",
      "64: 640x640 2 persons, 6.3ms\n",
      "65: 640x640 2 persons, 6.3ms\n",
      "66: 640x640 2 persons, 6.3ms\n",
      "67: 640x640 2 persons, 6.3ms\n",
      "68: 640x640 2 persons, 6.3ms\n",
      "69: 640x640 2 persons, 6.3ms\n",
      "70: 640x640 2 persons, 6.3ms\n",
      "71: 640x640 2 persons, 6.3ms\n",
      "72: 640x640 2 persons, 6.3ms\n",
      "73: 640x640 2 persons, 6.3ms\n",
      "74: 640x640 3 persons, 6.3ms\n",
      "75: 640x640 3 persons, 6.3ms\n",
      "76: 640x640 2 persons, 6.3ms\n",
      "77: 640x640 2 persons, 6.3ms\n",
      "78: 640x640 3 persons, 6.3ms\n",
      "79: 640x640 2 persons, 6.3ms\n",
      "80: 640x640 2 persons, 6.3ms\n",
      "81: 640x640 2 persons, 6.3ms\n",
      "82: 640x640 2 persons, 6.3ms\n",
      "83: 640x640 2 persons, 6.3ms\n",
      "84: 640x640 2 persons, 6.3ms\n",
      "85: 640x640 2 persons, 6.3ms\n",
      "86: 640x640 2 persons, 6.3ms\n",
      "87: 640x640 2 persons, 6.3ms\n",
      "88: 640x640 2 persons, 6.3ms\n",
      "89: 640x640 2 persons, 6.3ms\n",
      "90: 640x640 2 persons, 6.3ms\n",
      "91: 640x640 2 persons, 2 bottles, 6.3ms\n",
      "92: 640x640 2 persons, 2 bottles, 6.3ms\n",
      "93: 640x640 2 persons, 1 bottle, 6.3ms\n",
      "94: 640x640 2 persons, 6.3ms\n",
      "95: 640x640 2 persons, 6.3ms\n",
      "96: 640x640 2 persons, 6.3ms\n",
      "97: 640x640 2 persons, 6.3ms\n",
      "98: 640x640 2 persons, 6.3ms\n",
      "99: 640x640 2 persons, 6.3ms\n",
      "100: 640x640 2 persons, 6.3ms\n",
      "101: 640x640 2 persons, 6.3ms\n",
      "102: 640x640 2 persons, 6.3ms\n",
      "103: 640x640 2 persons, 6.3ms\n",
      "104: 640x640 2 persons, 6.3ms\n",
      "105: 640x640 2 persons, 6.3ms\n",
      "106: 640x640 2 persons, 6.3ms\n",
      "107: 640x640 2 persons, 6.3ms\n",
      "108: 640x640 2 persons, 6.3ms\n",
      "109: 640x640 2 persons, 6.3ms\n",
      "110: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "111: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "112: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "113: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "114: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "115: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "116: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "117: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "118: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "119: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "120: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "121: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "122: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "123: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "124: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "125: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "126: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "127: 640x640 2 persons, 2 benchs, 6.3ms\n",
      "Speed: 1.1ms preprocess, 6.3ms inference, 14.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed frame 130\n",
      "Processed frame 140\n",
      "Processed frame 150\n",
      "Processed frame 160\n",
      "Processed frame 170\n",
      "Processed frame 180\n",
      "Processed frame 190\n",
      "Processed frame 200\n",
      "Processed frame 210\n",
      "Processed frame 220\n",
      "Processed frame 230\n",
      "Processed frame 240\n",
      "Processed frame 250\n",
      "\n",
      "0: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "1: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "2: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "3: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "4: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "5: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "6: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "7: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "8: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "9: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "10: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "11: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "12: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "13: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "14: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "15: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "16: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "17: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "18: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "19: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "20: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "21: 640x640 2 persons, 2 benchs, 5.6ms\n",
      "22: 640x640 1 person, 5.6ms\n",
      "23: 640x640 1 person, 5.6ms\n",
      "24: 640x640 1 person, 5.6ms\n",
      "25: 640x640 1 person, 5.6ms\n",
      "26: 640x640 1 person, 5.6ms\n",
      "27: 640x640 1 person, 5.6ms\n",
      "28: 640x640 1 person, 5.6ms\n",
      "29: 640x640 1 person, 5.6ms\n",
      "30: 640x640 1 person, 5.6ms\n",
      "31: 640x640 1 person, 5.6ms\n",
      "32: 640x640 1 person, 5.6ms\n",
      "33: 640x640 1 person, 5.6ms\n",
      "34: 640x640 1 person, 5.6ms\n",
      "35: 640x640 1 person, 5.6ms\n",
      "36: 640x640 1 person, 5.6ms\n",
      "37: 640x640 1 person, 5.6ms\n",
      "38: 640x640 1 person, 5.6ms\n",
      "39: 640x640 1 person, 5.6ms\n",
      "40: 640x640 1 person, 5.6ms\n",
      "41: 640x640 1 person, 5.6ms\n",
      "42: 640x640 1 person, 5.6ms\n",
      "43: 640x640 1 person, 5.6ms\n",
      "44: 640x640 1 person, 2 cars, 5.6ms\n",
      "45: 640x640 1 person, 2 cars, 5.6ms\n",
      "46: 640x640 1 person, 2 cars, 5.6ms\n",
      "47: 640x640 1 person, 3 cars, 5.6ms\n",
      "48: 640x640 1 person, 3 cars, 5.6ms\n",
      "49: 640x640 1 person, 3 cars, 5.6ms\n",
      "50: 640x640 1 person, 2 cars, 5.6ms\n",
      "51: 640x640 1 person, 1 car, 5.6ms\n",
      "52: 640x640 1 person, 2 cars, 5.6ms\n",
      "53: 640x640 1 person, 1 car, 5.6ms\n",
      "54: 640x640 1 person, 1 car, 5.6ms\n",
      "55: 640x640 1 person, 1 car, 5.6ms\n",
      "56: 640x640 1 person, 1 car, 5.6ms\n",
      "57: 640x640 1 person, 1 car, 5.6ms\n",
      "58: 640x640 1 person, 1 car, 5.6ms\n",
      "59: 640x640 1 person, 2 cars, 5.6ms\n",
      "60: 640x640 1 person, 5.6ms\n",
      "61: 640x640 1 person, 1 car, 5.6ms\n",
      "62: 640x640 1 person, 5.6ms\n",
      "63: 640x640 1 person, 5.6ms\n",
      "64: 640x640 1 person, 5.6ms\n",
      "65: 640x640 1 person, 1 car, 1 cell phone, 5.6ms\n",
      "66: 640x640 1 person, 1 car, 5.6ms\n",
      "67: 640x640 1 person, 1 car, 5.6ms\n",
      "68: 640x640 1 person, 5.6ms\n",
      "69: 640x640 1 person, 5.6ms\n",
      "70: 640x640 1 person, 5.6ms\n",
      "71: 640x640 1 person, 1 car, 5.6ms\n",
      "72: 640x640 1 person, 5.6ms\n",
      "73: 640x640 1 person, 5.6ms\n",
      "74: 640x640 1 person, 5.6ms\n",
      "75: 640x640 1 person, 1 car, 5.6ms\n",
      "76: 640x640 1 person, 1 car, 5.6ms\n",
      "77: 640x640 1 person, 2 cars, 5.6ms\n",
      "78: 640x640 1 person, 1 car, 5.6ms\n",
      "79: 640x640 1 person, 1 car, 5.6ms\n",
      "80: 640x640 1 person, 1 car, 5.6ms\n",
      "81: 640x640 1 person, 5.6ms\n",
      "82: 640x640 1 person, 5.6ms\n",
      "83: 640x640 1 person, 5.6ms\n",
      "84: 640x640 1 person, 5.6ms\n",
      "85: 640x640 1 person, 5.6ms\n",
      "86: 640x640 (no detections), 5.6ms\n",
      "87: 640x640 1 cat, 5.6ms\n",
      "88: 640x640 (no detections), 5.6ms\n",
      "89: 640x640 (no detections), 5.6ms\n",
      "90: 640x640 (no detections), 5.6ms\n",
      "91: 640x640 (no detections), 5.6ms\n",
      "92: 640x640 (no detections), 5.6ms\n",
      "93: 640x640 (no detections), 5.6ms\n",
      "94: 640x640 (no detections), 5.6ms\n",
      "95: 640x640 (no detections), 5.6ms\n",
      "96: 640x640 (no detections), 5.6ms\n",
      "97: 640x640 (no detections), 5.6ms\n",
      "98: 640x640 1 person, 5.6ms\n",
      "99: 640x640 1 person, 5.6ms\n",
      "100: 640x640 1 person, 5.6ms\n",
      "101: 640x640 1 person, 5.6ms\n",
      "102: 640x640 1 person, 5.6ms\n",
      "103: 640x640 1 person, 5.6ms\n",
      "104: 640x640 1 person, 5.6ms\n",
      "105: 640x640 1 person, 5.6ms\n",
      "106: 640x640 1 person, 5.6ms\n",
      "107: 640x640 1 person, 5.6ms\n",
      "108: 640x640 1 person, 5.6ms\n",
      "109: 640x640 1 person, 5.6ms\n",
      "110: 640x640 1 person, 5.6ms\n",
      "111: 640x640 1 person, 5.6ms\n",
      "112: 640x640 1 person, 5.6ms\n",
      "113: 640x640 1 person, 5.6ms\n",
      "114: 640x640 1 person, 5.6ms\n",
      "115: 640x640 1 person, 5.6ms\n",
      "116: 640x640 1 person, 5.6ms\n",
      "117: 640x640 1 person, 5.6ms\n",
      "118: 640x640 1 person, 5.6ms\n",
      "119: 640x640 1 person, 5.6ms\n",
      "120: 640x640 1 person, 5.6ms\n",
      "121: 640x640 1 person, 5.6ms\n",
      "122: 640x640 1 person, 5.6ms\n",
      "123: 640x640 1 person, 5.6ms\n",
      "124: 640x640 1 person, 5.6ms\n",
      "125: 640x640 1 person, 5.6ms\n",
      "126: 640x640 1 person, 5.6ms\n",
      "127: 640x640 1 person, 5.6ms\n",
      "Speed: 1.2ms preprocess, 5.6ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed frame 260\n",
      "Processed frame 270\n",
      "Processed frame 280\n",
      "Processed frame 290\n",
      "Processed frame 300\n",
      "Processed frame 310\n",
      "Processed frame 320\n",
      "Processed frame 330\n",
      "Processed frame 340\n",
      "Processed frame 350\n",
      "Processed frame 360\n",
      "Processed frame 370\n",
      "Processed frame 380\n",
      "\n",
      "0: 640x640 1 person, 6.1ms\n",
      "1: 640x640 1 person, 6.1ms\n",
      "2: 640x640 1 person, 6.1ms\n",
      "3: 640x640 1 person, 6.1ms\n",
      "4: 640x640 1 person, 6.1ms\n",
      "5: 640x640 1 person, 6.1ms\n",
      "6: 640x640 1 person, 6.1ms\n",
      "7: 640x640 1 person, 6.1ms\n",
      "8: 640x640 1 person, 6.1ms\n",
      "9: 640x640 1 person, 6.1ms\n",
      "10: 640x640 1 person, 6.1ms\n",
      "11: 640x640 1 person, 6.1ms\n",
      "12: 640x640 1 person, 6.1ms\n",
      "13: 640x640 1 person, 6.1ms\n",
      "14: 640x640 1 person, 6.1ms\n",
      "15: 640x640 1 person, 6.1ms\n",
      "16: 640x640 1 person, 6.1ms\n",
      "17: 640x640 1 person, 1 chair, 6.1ms\n",
      "18: 640x640 1 person, 1 chair, 6.1ms\n",
      "19: 640x640 1 person, 1 chair, 6.1ms\n",
      "20: 640x640 1 person, 6.1ms\n",
      "21: 640x640 1 person, 1 chair, 6.1ms\n",
      "22: 640x640 1 person, 1 chair, 1 clock, 6.1ms\n",
      "23: 640x640 1 person, 1 chair, 6.1ms\n",
      "24: 640x640 1 person, 1 chair, 6.1ms\n",
      "25: 640x640 1 person, 1 chair, 6.1ms\n",
      "26: 640x640 1 person, 1 chair, 6.1ms\n",
      "27: 640x640 1 person, 1 chair, 6.1ms\n",
      "28: 640x640 1 person, 1 chair, 6.1ms\n",
      "29: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "30: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "31: 640x640 1 person, 1 chair, 6.1ms\n",
      "32: 640x640 1 person, 1 chair, 6.1ms\n",
      "33: 640x640 1 person, 1 chair, 6.1ms\n",
      "34: 640x640 1 person, 1 chair, 6.1ms\n",
      "35: 640x640 1 person, 1 chair, 6.1ms\n",
      "36: 640x640 1 person, 1 chair, 6.1ms\n",
      "37: 640x640 1 person, 1 chair, 6.1ms\n",
      "38: 640x640 1 person, 1 chair, 6.1ms\n",
      "39: 640x640 1 person, 1 chair, 6.1ms\n",
      "40: 640x640 1 person, 1 chair, 6.1ms\n",
      "41: 640x640 1 person, 1 chair, 6.1ms\n",
      "42: 640x640 1 person, 1 chair, 6.1ms\n",
      "43: 640x640 1 person, 1 chair, 6.1ms\n",
      "44: 640x640 1 person, 1 chair, 6.1ms\n",
      "45: 640x640 1 person, 1 chair, 6.1ms\n",
      "46: 640x640 1 person, 1 chair, 6.1ms\n",
      "47: 640x640 1 person, 1 chair, 6.1ms\n",
      "48: 640x640 1 person, 1 chair, 6.1ms\n",
      "49: 640x640 1 person, 1 chair, 6.1ms\n",
      "50: 640x640 1 person, 1 chair, 6.1ms\n",
      "51: 640x640 1 person, 1 chair, 6.1ms\n",
      "52: 640x640 1 person, 1 chair, 6.1ms\n",
      "53: 640x640 1 person, 1 chair, 6.1ms\n",
      "54: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "55: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "56: 640x640 1 person, 1 chair, 6.1ms\n",
      "57: 640x640 1 person, 1 chair, 6.1ms\n",
      "58: 640x640 1 person, 1 chair, 6.1ms\n",
      "59: 640x640 1 person, 1 chair, 6.1ms\n",
      "60: 640x640 1 person, 1 chair, 6.1ms\n",
      "61: 640x640 1 person, 1 chair, 6.1ms\n",
      "62: 640x640 1 person, 1 chair, 6.1ms\n",
      "63: 640x640 1 person, 1 chair, 6.1ms\n",
      "64: 640x640 1 person, 1 chair, 6.1ms\n",
      "65: 640x640 1 person, 1 chair, 6.1ms\n",
      "66: 640x640 1 person, 1 chair, 6.1ms\n",
      "67: 640x640 1 person, 1 chair, 6.1ms\n",
      "68: 640x640 1 person, 6.1ms\n",
      "69: 640x640 1 person, 1 chair, 6.1ms\n",
      "70: 640x640 1 person, 1 chair, 6.1ms\n",
      "71: 640x640 1 person, 1 chair, 6.1ms\n",
      "72: 640x640 1 person, 1 chair, 6.1ms\n",
      "73: 640x640 1 person, 6.1ms\n",
      "74: 640x640 1 person, 6.1ms\n",
      "75: 640x640 1 person, 1 chair, 6.1ms\n",
      "76: 640x640 1 person, 6.1ms\n",
      "77: 640x640 1 person, 6.1ms\n",
      "78: 640x640 1 person, 6.1ms\n",
      "79: 640x640 1 person, 6.1ms\n",
      "80: 640x640 1 person, 1 clock, 6.1ms\n",
      "81: 640x640 1 person, 6.1ms\n",
      "82: 640x640 1 person, 6.1ms\n",
      "83: 640x640 1 person, 6.1ms\n",
      "84: 640x640 1 person, 6.1ms\n",
      "85: 640x640 1 person, 6.1ms\n",
      "86: 640x640 1 person, 1 cup, 6.1ms\n",
      "87: 640x640 1 person, 1 cup, 6.1ms\n",
      "88: 640x640 1 person, 1 cup, 6.1ms\n",
      "89: 640x640 1 person, 1 cup, 6.1ms\n",
      "90: 640x640 1 person, 1 cup, 6.1ms\n",
      "91: 640x640 1 person, 1 cup, 6.1ms\n",
      "92: 640x640 1 person, 1 cup, 6.1ms\n",
      "93: 640x640 1 person, 1 cup, 6.1ms\n",
      "94: 640x640 1 person, 1 cup, 6.1ms\n",
      "95: 640x640 1 person, 1 cup, 6.1ms\n",
      "96: 640x640 1 person, 1 cup, 6.1ms\n",
      "97: 640x640 1 person, 1 cup, 6.1ms\n",
      "98: 640x640 1 person, 1 cup, 6.1ms\n",
      "99: 640x640 1 person, 1 cup, 6.1ms\n",
      "100: 640x640 1 person, 1 cup, 6.1ms\n",
      "101: 640x640 1 person, 1 cup, 6.1ms\n",
      "102: 640x640 1 person, 1 cup, 6.1ms\n",
      "103: 640x640 1 person, 6.1ms\n",
      "104: 640x640 1 person, 1 cup, 6.1ms\n",
      "105: 640x640 1 person, 6.1ms\n",
      "106: 640x640 1 person, 6.1ms\n",
      "107: 640x640 1 person, 1 chair, 6.1ms\n",
      "108: 640x640 1 person, 1 chair, 6.1ms\n",
      "109: 640x640 1 person, 1 chair, 6.1ms\n",
      "110: 640x640 1 person, 1 cup, 1 chair, 6.1ms\n",
      "111: 640x640 1 person, 1 cup, 1 chair, 6.1ms\n",
      "112: 640x640 1 person, 1 chair, 6.1ms\n",
      "113: 640x640 1 person, 6.1ms\n",
      "114: 640x640 1 person, 6.1ms\n",
      "115: 640x640 1 person, 1 cup, 1 chair, 6.1ms\n",
      "116: 640x640 1 person, 1 bottle, 1 cup, 6.1ms\n",
      "117: 640x640 1 person, 1 chair, 6.1ms\n",
      "118: 640x640 1 person, 1 chair, 1 cell phone, 6.1ms\n",
      "119: 640x640 1 person, 1 chair, 1 cell phone, 6.1ms\n",
      "120: 640x640 1 person, 1 chair, 1 remote, 1 cell phone, 6.1ms\n",
      "121: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "122: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "123: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "124: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "125: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "126: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "127: 640x640 1 person, 1 chair, 1 remote, 6.1ms\n",
      "Speed: 1.1ms preprocess, 6.1ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed frame 390\n",
      "Processed frame 400\n",
      "Processed frame 410\n",
      "Processed frame 420\n",
      "Processed frame 430\n",
      "Processed frame 440\n",
      "Processed frame 450\n",
      "Processed frame 460\n",
      "Processed frame 470\n",
      "Processed frame 480\n",
      "Processed frame 490\n",
      "Processed frame 500\n",
      "Processed frame 510\n",
      "\n",
      "0: 640x640 1 person, 1 chair, 1 remote, 5.9ms\n",
      "1: 640x640 1 person, 1 remote, 5.9ms\n",
      "2: 640x640 1 person, 1 remote, 5.9ms\n",
      "3: 640x640 1 person, 1 remote, 5.9ms\n",
      "4: 640x640 1 person, 1 remote, 5.9ms\n",
      "5: 640x640 1 person, 1 remote, 5.9ms\n",
      "6: 640x640 1 person, 1 chair, 1 remote, 1 cell phone, 5.9ms\n",
      "7: 640x640 1 person, 1 remote, 1 cell phone, 5.9ms\n",
      "8: 640x640 1 person, 1 chair, 1 remote, 5.9ms\n",
      "9: 640x640 1 person, 2 laptops, 5.9ms\n",
      "10: 640x640 1 person, 2 laptops, 5.9ms\n",
      "11: 640x640 1 person, 1 laptop, 5.9ms\n",
      "12: 640x640 1 person, 2 laptops, 5.9ms\n",
      "13: 640x640 1 person, 2 laptops, 5.9ms\n",
      "14: 640x640 1 person, 2 laptops, 5.9ms\n",
      "15: 640x640 1 person, 2 laptops, 5.9ms\n",
      "16: 640x640 1 person, 2 laptops, 5.9ms\n",
      "17: 640x640 1 person, 2 laptops, 5.9ms\n",
      "18: 640x640 1 person, 2 laptops, 5.9ms\n",
      "19: 640x640 1 person, 2 laptops, 5.9ms\n",
      "20: 640x640 1 person, 2 laptops, 5.9ms\n",
      "21: 640x640 1 person, 2 laptops, 5.9ms\n",
      "22: 640x640 1 person, 3 laptops, 5.9ms\n",
      "23: 640x640 1 person, 2 laptops, 5.9ms\n",
      "24: 640x640 1 person, 3 laptops, 5.9ms\n",
      "25: 640x640 1 person, 2 laptops, 5.9ms\n",
      "26: 640x640 1 person, 2 laptops, 5.9ms\n",
      "27: 640x640 1 person, 2 laptops, 5.9ms\n",
      "28: 640x640 1 person, 2 laptops, 5.9ms\n",
      "29: 640x640 1 person, 2 laptops, 5.9ms\n",
      "30: 640x640 1 person, 2 laptops, 5.9ms\n",
      "31: 640x640 1 person, 2 laptops, 5.9ms\n",
      "32: 640x640 1 person, 2 laptops, 5.9ms\n",
      "33: 640x640 3 persons, 1 couch, 1 potted plant, 1 laptop, 5.9ms\n",
      "34: 640x640 3 persons, 1 couch, 1 potted plant, 1 laptop, 5.9ms\n",
      "35: 640x640 3 persons, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "36: 640x640 3 persons, 1 handbag, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "37: 640x640 3 persons, 1 handbag, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "38: 640x640 3 persons, 1 handbag, 1 couch, 2 potted plants, 5.9ms\n",
      "39: 640x640 3 persons, 1 couch, 2 potted plants, 5.9ms\n",
      "40: 640x640 3 persons, 1 couch, 2 potted plants, 5.9ms\n",
      "41: 640x640 3 persons, 1 couch, 2 potted plants, 5.9ms\n",
      "42: 640x640 3 persons, 1 couch, 2 potted plants, 5.9ms\n",
      "43: 640x640 3 persons, 1 couch, 2 potted plants, 5.9ms\n",
      "44: 640x640 3 persons, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "45: 640x640 3 persons, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "46: 640x640 3 persons, 1 handbag, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "47: 640x640 3 persons, 1 handbag, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "48: 640x640 3 persons, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "49: 640x640 3 persons, 1 couch, 2 potted plants, 1 laptop, 5.9ms\n",
      "50: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 1 remote, 5.9ms\n",
      "51: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 1 vase, 5.9ms\n",
      "52: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 1 vase, 5.9ms\n",
      "53: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 5.9ms\n",
      "54: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 5.9ms\n",
      "55: 640x640 3 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 5.9ms\n",
      "56: 640x640 3 persons, 1 couch, 3 potted plants, 1 tv, 1 laptop, 5.9ms\n",
      "57: 640x640 3 persons, 1 couch, 1 tv, 1 laptop, 5.9ms\n",
      "58: 640x640 3 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 5.9ms\n",
      "59: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 5.9ms\n",
      "60: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 5.9ms\n",
      "61: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 5.9ms\n",
      "62: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 5.9ms\n",
      "63: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 5.9ms\n",
      "64: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 2 vases, 5.9ms\n",
      "65: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 5.9ms\n",
      "66: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 laptop, 5.9ms\n",
      "67: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 1 vase, 5.9ms\n",
      "68: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 laptop, 1 vase, 5.9ms\n",
      "69: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 5.9ms\n",
      "70: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 5.9ms\n",
      "71: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 5.9ms\n",
      "72: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "73: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 5.9ms\n",
      "74: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "75: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 remote, 1 vase, 5.9ms\n",
      "76: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "77: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "78: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "79: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 5.9ms\n",
      "80: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "81: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "82: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "83: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "84: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "85: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "86: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "87: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "88: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 cell phone, 1 vase, 5.9ms\n",
      "89: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 cell phone, 1 vase, 5.9ms\n",
      "90: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 cell phone, 1 vase, 5.9ms\n",
      "91: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "92: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "93: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "94: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "95: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.9ms\n",
      "96: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "97: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "98: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "99: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "100: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "101: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "102: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "103: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "104: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "105: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "106: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "107: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 cell phone, 1 vase, 5.9ms\n",
      "108: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 cell phone, 1 vase, 5.9ms\n",
      "109: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "110: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "111: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "112: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "113: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "114: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "115: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "116: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "117: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.9ms\n",
      "118: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.9ms\n",
      "119: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.9ms\n",
      "120: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.9ms\n",
      "121: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.9ms\n",
      "122: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.9ms\n",
      "123: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "124: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "125: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "126: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "127: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Processed frame 520\n",
      "Processed frame 530\n",
      "Processed frame 540\n",
      "Processed frame 550\n",
      "Processed frame 560\n",
      "Processed frame 570\n",
      "Processed frame 580\n",
      "Processed frame 590\n",
      "Processed frame 600\n",
      "Processed frame 610\n",
      "Processed frame 620\n",
      "\n",
      "0: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "1: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "2: 640x640 2 persons, 1 couch, 1 tv, 5.8ms\n",
      "3: 640x640 2 persons, 1 couch, 1 tv, 5.8ms\n",
      "4: 640x640 2 persons, 1 couch, 1 tv, 5.8ms\n",
      "5: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 5.8ms\n",
      "6: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 5.8ms\n",
      "7: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 5.8ms\n",
      "8: 640x640 3 persons, 1 couch, 1 potted plant, 1 tv, 5.8ms\n",
      "9: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "10: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "11: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "12: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "13: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "14: 640x640 2 persons, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "15: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "16: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "17: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 2 vases, 5.8ms\n",
      "18: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 2 vases, 5.8ms\n",
      "19: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "20: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "21: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "22: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "23: 640x640 2 persons, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "24: 640x640 2 persons, 1 chair, 1 couch, 2 potted plants, 1 tv, 1 vase, 5.8ms\n",
      "25: 640x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "26: 640x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "27: 640x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 tv, 1 vase, 5.8ms\n",
      "28: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "29: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "30: 640x640 2 persons, 1 couch, 2 potted plants, 5.8ms\n",
      "31: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "32: 640x640 2 persons, 1 couch, 2 potted plants, 5.8ms\n",
      "33: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "34: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "35: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "36: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "37: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "38: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "39: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "40: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "41: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "42: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "43: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "44: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "45: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "46: 640x640 2 persons, 1 couch, 1 potted plant, 5.8ms\n",
      "47: 640x640 2 persons, 1 couch, 2 potted plants, 5.8ms\n",
      "48: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "49: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "50: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "51: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "52: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "53: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "54: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "55: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "56: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "57: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "58: 640x640 2 persons, 1 chair, 1 couch, 2 potted plants, 1 cell phone, 1 vase, 5.8ms\n",
      "59: 640x640 2 persons, 1 chair, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "60: 640x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "61: 640x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "62: 640x640 2 persons, 1 chair, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "63: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "64: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "65: 640x640 2 persons, 1 chair, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "66: 640x640 2 persons, 1 chair, 1 couch, 2 potted plants, 1 remote, 1 vase, 5.8ms\n",
      "67: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "68: 640x640 2 persons, 1 couch, 1 potted plant, 1 remote, 1 vase, 5.8ms\n",
      "69: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "70: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "71: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "72: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "73: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "74: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "75: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "76: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "77: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "78: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "79: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "80: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "81: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "82: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "83: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "84: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "85: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "86: 640x640 2 persons, 1 couch, 2 potted plants, 1 vase, 5.8ms\n",
      "87: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "88: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "89: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "90: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "91: 640x640 2 persons, 1 couch, 2 potted plants, 2 vases, 5.8ms\n",
      "92: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "93: 640x640 2 persons, 1 couch, 1 potted plant, 2 vases, 5.8ms\n",
      "94: 640x640 2 persons, 1 couch, 1 potted plant, 2 vases, 5.8ms\n",
      "95: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "96: 640x640 2 persons, 1 couch, 1 vase, 5.8ms\n",
      "97: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "98: 640x640 2 persons, 1 couch, 1 vase, 5.8ms\n",
      "99: 640x640 2 persons, 1 couch, 1 vase, 5.8ms\n",
      "100: 640x640 2 persons, 1 couch, 1 vase, 5.8ms\n",
      "101: 640x640 2 persons, 1 couch, 1 vase, 5.8ms\n",
      "102: 640x640 2 persons, 1 couch, 1 vase, 5.8ms\n",
      "103: 640x640 2 persons, 1 couch, 2 vases, 5.8ms\n",
      "104: 640x640 2 persons, 1 couch, 2 vases, 5.8ms\n",
      "105: 640x640 2 persons, 1 couch, 2 vases, 5.8ms\n",
      "106: 640x640 2 persons, 1 couch, 2 vases, 5.8ms\n",
      "107: 640x640 2 persons, 1 couch, 2 vases, 5.8ms\n",
      "108: 640x640 2 persons, 1 couch, 2 vases, 5.8ms\n",
      "109: 640x640 2 persons, 1 couch, 2 vases, 5.8ms\n",
      "110: 640x640 2 persons, 1 couch, 1 vase, 5.8ms\n",
      "111: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "112: 640x640 2 persons, 1 couch, 1 potted plant, 1 vase, 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Detection data saved\n",
      "\n",
      "Loading detection data...\n",
      "Total frames processed: 625\n"
     ]
    }
   ],
   "source": [
    "process_video()\n",
    "\n",
    "# Example of loading and using the detection data\n",
    "print(\"\\nLoading detection data...\")\n",
    "all_detections = load_detections()\n",
    "print(f\"Total frames processed: {len(all_detections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1735974822465,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "EsYwo50PRrZj"
   },
   "outputs": [],
   "source": [
    "def transform_jsonl(input_file):\n",
    "    transformed_data = []\n",
    "\n",
    "    # Open and read the JSONL file\n",
    "    with open(input_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse each line as JSON\n",
    "            frame_data = json.loads(line.strip())\n",
    "            frame_number = frame_data[\"frame_number\"]\n",
    "            bounding_boxes = [detection[\"bbox\"] for detection in frame_data[\"detections\"]]\n",
    "            transformed_data.append({\"frame_number\": frame_number, \"bounding_boxes\": bounding_boxes})\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "detections_list = transform_jsonl(DETECTIONS_FILE_PATH)\n",
    "# print(detections_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1735974822465,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "nFJma-EMPSRV"
   },
   "outputs": [],
   "source": [
    "def calculate_916_crop(frame_data, image_width, image_height):\n",
    "    # Extract bounding boxes from the frame data\n",
    "    bounding_boxes = frame_data.get(\"bounding_boxes\", [])\n",
    "\n",
    "    # Define 9:16 target ratio\n",
    "    target_ratio = 9 / 16\n",
    "\n",
    "    # Determine fixed crop dimensions based on video size\n",
    "    if image_width / image_height > target_ratio:\n",
    "        # Height is limiting factor\n",
    "        crop_height = image_height\n",
    "        crop_width = crop_height * target_ratio\n",
    "    else:\n",
    "        # Width is limiting factor\n",
    "        crop_width = image_width\n",
    "        crop_height = crop_width / target_ratio\n",
    "\n",
    "    # Add padding if desired (e.g., 10%)\n",
    "    padding_factor = 1.1\n",
    "    crop_width *= padding_factor\n",
    "    crop_height *= padding_factor\n",
    "\n",
    "    # Ensure crop doesn't exceed image dimensions\n",
    "    crop_width = min(crop_width, image_width)\n",
    "    crop_height = min(crop_height, image_height)\n",
    "\n",
    "    # Handle bounding_boxes\n",
    "    if not bounding_boxes:\n",
    "        center_x, center_y = image_width / 2, image_height / 2\n",
    "    else:\n",
    "        # Find the largest object (by area) in the bounding boxes\n",
    "        largest_box = max(\n",
    "            bounding_boxes,\n",
    "            key=lambda box: (box[2] - box[0]) * (box[3] - box[1])\n",
    "        )\n",
    "        box_width = largest_box[2] - largest_box[0]\n",
    "        box_height = largest_box[3] - largest_box[1]\n",
    "\n",
    "        # Determine if the box is too large for the crop dimensions\n",
    "        if box_width > crop_width or box_height > crop_height:\n",
    "            # Focus on the center of the box\n",
    "            center_x = (largest_box[0] + largest_box[2]) / 2\n",
    "            center_y = (largest_box[1] + largest_box[3]) / 2\n",
    "        else:\n",
    "            # Focus on the top-left corner of the box\n",
    "            center_x = largest_box[0]\n",
    "            center_y = largest_box[1]\n",
    "\n",
    "    # Calculate initial crop coordinates\n",
    "    x1 = max(0, center_x - crop_width / 2)\n",
    "    y1 = max(0, center_y - crop_height / 2)\n",
    "    x2 = x1 + crop_width\n",
    "    y2 = y1 + crop_height\n",
    "\n",
    "    # Adjust crop if it exceeds boundaries\n",
    "    if x2 > image_width:\n",
    "        x2 = image_width\n",
    "        x1 = x2 - crop_width\n",
    "    if y2 > image_height:\n",
    "        y2 = image_height\n",
    "        y1 = y2 - crop_height\n",
    "    if x1 < 0:\n",
    "        x1 = 0\n",
    "        x2 = crop_width\n",
    "    if y1 < 0:\n",
    "        y1 = 0\n",
    "        y2 = crop_height\n",
    "\n",
    "    # Ensure crop coordinates stay within the image boundaries\n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = min(image_width, x2)\n",
    "    y2 = min(image_height, y2)\n",
    "\n",
    "    return [int(x1), int(y1), int(x2), int(y2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1735974822465,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "xSPFWQ4sg38W"
   },
   "outputs": [],
   "source": [
    "# def process_video_with_boxes(video_path, detections_list, output_path, smoothing_factor=0.95):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "#     frame_count = 0\n",
    "#     color = (0, 255, 0)\n",
    "#     thickness = 2\n",
    "\n",
    "#     # Initialize previous crop coordinates\n",
    "#     previous_crop_coords = None\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         if frame_count < len(detections_list):\n",
    "#             boxes = detections_list[frame_count]\n",
    "#             # Calculate current crop coordinates\n",
    "#             current_crop_coords = calculate_916_crop(boxes, width, height)\n",
    "\n",
    "#             if previous_crop_coords is None:\n",
    "#                 # First frame, no smoothing applied\n",
    "#                 smoothed_crop_coords = current_crop_coords\n",
    "#             else:\n",
    "#                 # Apply exponential smoothing\n",
    "#                 smoothed_crop_coords = [\n",
    "#                     int(previous_crop_coords[i] * smoothing_factor + current_crop_coords[i] * (1 - smoothing_factor))\n",
    "#                     for i in range(4)\n",
    "#                 ]\n",
    "\n",
    "#             # Draw the smoothed crop rectangle on the frame\n",
    "#             cv2.rectangle(\n",
    "#                 frame,\n",
    "#                 (smoothed_crop_coords[0], smoothed_crop_coords[1]),\n",
    "#                 (smoothed_crop_coords[2], smoothed_crop_coords[3]),\n",
    "#                 color, thickness\n",
    "#             )\n",
    "\n",
    "#             # Update the previous crop coordinates\n",
    "#             previous_crop_coords = smoothed_crop_coords\n",
    "\n",
    "#         out.write(frame)\n",
    "#         frame_count += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "\n",
    "# # Make sure `detections_list` and `calculate_916_crop` are properly defined\n",
    "# process_video_with_boxes(MAIN_INPUT_PATH, detections_list, ANNOTATED_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 12760,
     "status": "ok",
     "timestamp": 1735975337776,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "vyU0lHxQkTUj"
   },
   "outputs": [],
   "source": [
    "def cut_video_with_smoothing(video_path, detections_list, output_path, output_width=1080, output_height=1920, smoothing_factor=0.95):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (output_width, output_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    color = (0, 255, 0)\n",
    "    thickness = 2\n",
    "\n",
    "    # Initialize previous crop coordinates\n",
    "    previous_crop_coords = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count < len(detections_list):\n",
    "            boxes = detections_list[frame_count]\n",
    "            # Calculate current crop coordinates\n",
    "            current_crop_coords = calculate_916_crop(boxes, width, height)\n",
    "\n",
    "            if previous_crop_coords is None:\n",
    "                # First frame, no smoothing applied\n",
    "                smoothed_crop_coords = current_crop_coords\n",
    "            else:\n",
    "                # Apply exponential smoothing\n",
    "                smoothed_crop_coords = [\n",
    "                    int(previous_crop_coords[i] * smoothing_factor + current_crop_coords[i] * (1 - smoothing_factor))\n",
    "                    for i in range(4)\n",
    "                ]\n",
    "\n",
    "            # Crop the frame using the smoothed coordinates (adjusted to 9:16 aspect ratio)\n",
    "            cropped_frame = frame[smoothed_crop_coords[1]:smoothed_crop_coords[3], smoothed_crop_coords[0]:smoothed_crop_coords[2]]\n",
    "\n",
    "            # Resize the cropped frame to the desired 9:16 aspect ratio (output_width x output_height)\n",
    "            cropped_frame_resized = cv2.resize(cropped_frame, (output_width, output_height))\n",
    "\n",
    "            # Write the resized cropped frame to the output video\n",
    "            out.write(cropped_frame_resized)\n",
    "\n",
    "            # Update the previous crop coordinates\n",
    "            previous_crop_coords = smoothed_crop_coords\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "cut_video_with_smoothing(MAIN_INPUT_PATH, detections_list, MAIN_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79673,
     "status": "ok",
     "timestamp": 1735975245520,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "oNyUlVpVyZV4",
    "outputId": "5d7ff7b9-9af8-423f-debf-cb67da49d138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /content/output_video.mp4_temp.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /content/output_video.mp4_temp.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/output_video.mp4_temp.mp4\n"
     ]
    }
   ],
   "source": [
    "def add_sound_to_cuted_video(original_video_path, new_video_path, output_path):\n",
    "    try:\n",
    "        # Load the original video to extract its audio\n",
    "        original_video = VideoFileClip(original_video_path)\n",
    "        if original_video.audio is None:\n",
    "            raise ValueError(\"Original video has no audio track\")\n",
    "        original_audio = original_video.audio\n",
    "\n",
    "        # Load the edited video\n",
    "        edited_video = VideoFileClip(new_video_path)\n",
    "\n",
    "        # Get durations\n",
    "        original_audio_duration = original_audio.duration\n",
    "        edited_video_duration = edited_video.duration\n",
    "\n",
    "        # Handle cases based on video lengths\n",
    "        if original_audio_duration >= edited_video_duration:\n",
    "            # Trim the original audio to match the edited video\n",
    "            trimmed_audio = original_audio.subclip(0, edited_video_duration)\n",
    "            final_video = edited_video.set_audio(trimmed_audio)\n",
    "        else:\n",
    "            # Cut the edited video to match the original audio duration\n",
    "            trimmed_video = edited_video.subclip(0, original_audio_duration)\n",
    "            final_video = trimmed_video.set_audio(original_audio)\n",
    "\n",
    "        # Write to a temporary file first\n",
    "        temp_output_path = output_path + \"_temp.mp4\"\n",
    "        final_video.write_videofile(\n",
    "            temp_output_path,\n",
    "            codec=\"libx264\",\n",
    "            audio_codec=\"aac\",\n",
    "            temp_audiofile=\"temp-audio.m4a\",\n",
    "            remove_temp=True,\n",
    "            audio=True,  # Explicitly enable audio\n",
    "            ffmpeg_params=[\"-strict\", \"-2\"]  # Add FFmpeg parameters for better compatibility\n",
    "        )\n",
    "\n",
    "        # Replace the original file after successful export\n",
    "        os.replace(temp_output_path, output_path)\n",
    "\n",
    "        # Clean up by closing the video files\n",
    "        original_video.close()\n",
    "        edited_video.close()\n",
    "        final_video.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video: {str(e)}\")\n",
    "        # Clean up if there's an error\n",
    "        if 'original_video' in locals(): original_video.close()\n",
    "        if 'edited_video' in locals(): edited_video.close()\n",
    "        if 'final_video' in locals(): final_video.close()\n",
    "        if os.path.exists(temp_output_path): os.remove(temp_output_path)\n",
    "        raise\n",
    "\n",
    "add_sound_to_cuted_video(MAIN_INPUT_PATH, MAIN_OUTPUT_PATH, MAIN_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1735975245521,
     "user": {
      "displayName": "Neel Shah",
      "userId": "14076272843864918997"
     },
     "user_tz": -330
    },
    "id": "qo5IkSvGpYFu",
    "outputId": "1eb4082c-0f69-4843-9074-1fd66b1342d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/Solutions/eleven.mp4'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move(MAIN_OUTPUT_PATH, DESTINATION_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
