{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPm4OAf/+EtxwR9fs+VG0Og"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_oPfm0OI2qO","executionInfo":{"status":"ok","timestamp":1735758263794,"user_tz":-330,"elapsed":23879,"user":{"displayName":"Neel Shah","userId":"14076272843864918997"}},"outputId":"edac420c-a01e-4c45-8e0c-53e76f345f54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install anthropic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3K6gXFyKOjR","executionInfo":{"status":"ok","timestamp":1735756677354,"user_tz":-330,"elapsed":3264,"user":{"displayName":"Neel Shah","userId":"14076272843864918997"}},"outputId":"1cf8a931-fd3d-42b7-cc7d-06dbb7e4e74f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting anthropic\n","  Downloading anthropic-0.42.0-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.8.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.10.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.1)\n","Downloading anthropic-0.42.0-py3-none-any.whl (203 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/203.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/203.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: anthropic\n","Successfully installed anthropic-0.42.0\n"]}]},{"cell_type":"code","source":["# API_KEY = \"\""],"metadata":{"id":"YtBGvEPbOYxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import base64\n","from anthropic import Anthropic\n","import json\n","import re\n","\n","num_images = 5\n","\n","def analyze_video_frames_unique(video_path, api_key):\n","    client = Anthropic(api_key=api_key)\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    interval = total_frames // num_images\n","\n","    frames_base64 = []\n","    for i in range(num_images):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n","        ret, frame = cap.read()\n","        if ret:\n","            _, buffer = cv2.imencode('.jpg', frame)\n","            frames_base64.append(base64.b64encode(buffer).decode('utf-8'))\n","\n","    cap.release()\n","\n","    messages = [{\n","        \"role\": \"user\",\n","        \"content\": [\n","            {\n","                \"type\": \"text\",\n","                \"text\": \"\"\"Return ONLY a JSON array with exactly 2 items containing unique main objects from these frames. Rules:\n","                1. Format: [\"Object1\", \"Object2\"] or [\"Object1\", null]\n","                2. Maximum 2 unique objects\n","                3. No explanation text, just the JSON array\"\"\"\n","            }\n","        ]\n","    }]\n","\n","    for img_base64 in frames_base64:\n","        messages[0][\"content\"].append({\n","            \"type\": \"image\",\n","            \"source\": {\n","                \"type\": \"base64\",\n","                \"media_type\": \"image/jpeg\",\n","                \"data\": img_base64\n","            }\n","        })\n","\n","    response = client.messages.create(\n","        model=\"claude-3-haiku-20240307\",\n","        max_tokens=150,\n","        messages=messages\n","    )\n","\n","    # Extract JSON array using regex\n","    json_match = re.search(r'\\[.*?\\]', response.content[0].text)\n","    if json_match:\n","        return json.loads(json_match.group())\n","    return [None, None]\n","\n","api_key = API_KEY\n","video_path = \"/content/drive/MyDrive/Genuin Assignment/single_class_ip/o9tzeZckDgE.mp4\"\n","unique_objects = analyze_video_frames_unique(video_path, api_key)\n","print(unique_objects)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ft-uaLYMgJT","executionInfo":{"status":"ok","timestamp":1735757732619,"user_tz":-330,"elapsed":16057,"user":{"displayName":"Neel Shah","userId":"14076272843864918997"}},"outputId":"4d154d68-cc18-4289-ce59-85c5b3012e9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Person', 'Surfboard']\n"]}]}]}